# -*- coding: utf-8 -*-
"""Final_Edits.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nK7bnAFOiEjBWdd9MTErh9OLghqw-NCA
"""

pip install category_encoders

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
import category_encoders as ce
from sklearn.preprocessing import LabelEncoder

df = pd.read_csv("/content/vehicle fraud .csv")

df.head()

df.info()

df.isnull().sum()

df.columns

for column in df:
    print(column,":\n",df[column].unique(),'\n')

df.describe().T

df.describe(include= object).T

df.nunique()

df.hist(figsize=(15,10))

df_month = df.groupby(['Month']).size().reset_index().rename(columns={0:'Num_accidents'})
df_month

sns.countplot(data =df['Month'], x = df['MonthClaimed'])
plt.xticks(rotation = 55, horizontalalignment='right')
plt.ylabel('Num. of claims')
plt.show()

df['MonthName'] = pd.Categorical(df['Month'], ['Jan', 'Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'])
df['MonthName']

df['FraudFound_P'].value_counts()

print("The number of non fraudster claims is: ",len(df[df['FraudFound_P'] == 0]))
print("The number of fraudster claims is: ",len(df[df['FraudFound_P'] == 1]))
print("The number of total claims is: ",len(df['FraudFound_P']))

df[['Month','FraudFound_P']].groupby(['Month','FraudFound_P']).size().reset_index()

plt.figure(figsize=(12, 8))
labels = ['No Fraud', 'Fraud']
fig = sns.countplot(x="MonthName", hue ='FraudFound_P', data=df)
fig.bar_label(fig.containers[0], label_type='edge');

plt.legend(labels,  bbox_to_anchor=(1.2, 1))
plt.title('Fraud/No Fraud distribution by Month')
plt.ylabel('N. of claims')
plt.show()

df.groupby(['AccidentArea']).size().reset_index().rename(columns={0:'Num_accidents'})

Urban_claims=df.loc[df['AccidentArea']=='Urban'].groupby(['FraudFound_P']).size().reset_index().rename(index = {0:'No_Fraud',1:'Fraud'}, columns={0:'Num_accidents'})
Urban_claims

Rural_claims=df.loc[df['AccidentArea']=='Rural'].groupby(['FraudFound_P']).size().reset_index().rename(index = {0:'No_Fraud',1:'Fraud'}, columns={0:'Num_accidents'})
Rural_claims

Accident_area = df.AccidentArea.value_counts().values
labels = ['Urban','Rural']
plt.pie(Accident_area, labels = labels, autopct = '%1.2f%%')
plt.show()

"""Most claims are coming from urban area than the Rural area"""

area = ['Rural', 'Urban']
df['AreaType'] = pd.Categorical(df['AccidentArea'], categories=area, ordered=True)
df = df.sort_values('AreaType')

plt.figure(figsize=(7,5))
labels = ['No Fraud', 'Fraud']
sns.countplot(x="AreaType", hue ='FraudFound_P', data=df)
plt.legend(labels)
plt.title('Fraud/No Fraud distribution by Area')
plt.ylabel('N. of claims')
plt.show()

"""The Graph shows most frauds have been recorded in urban areas"""

df['Sex'].value_counts()

df['DriverRating'].value_counts()

Sex = df['Sex'].value_counts()
labels = ['Male','Female']
plt.pie(Sex,labels = labels, autopct = '%1.2f%%')
plt.show()

"""Most of the claims are filed by Men compared to Women

"""

plt.figure(figsize=(7, 5))
labels = ['No Fraud', 'Fraud']
sns.countplot(x="Sex",hue="FraudFound_P" ,data=df)
plt.legend(labels)
plt.title('Fraud distribution by Policy Type')
plt.xlabel('Sex')
plt.ylabel('N. of claims')
plt.show()

"""From the graph, we can see the fraudelent claims have been given mostly by men :

"""

plt.figure(figsize = (10,5))
sns.countplot(x = 'DriverRating', hue = 'Sex', data = df)
plt.legend(labels = ['Male','Female'], loc = 'upper right')
plt.ylabel('Num. of claims')
plt.xlabel('Driver rating')
plt.title('Driver rating by sex')
plt.show()

df['MaritalStatus'].value_counts()

df.groupby(['MaritalStatus', 'FraudFound_P']).size().reset_index()

plt.figure(figsize = (10,5))
sns.countplot(x = 'MaritalStatus', hue = 'FraudFound_P', data = df)
plt.title('Claims classified by marital status')
plt.legend(labels =['No Fraud','Fraud'])
plt.ylabel('Num. of claims')
plt.show()

"""Married people have given more fraudelent claims than the Other class pepople .

"""

df.boxplot(column = 'Age',figsize=(5,5))
plt.xticks(rotation = 55)
plt.show()

df[df['Age'] < 16].count()

df_fraud1 = df.loc[df['FraudFound_P'] == 1]
df_no_fraud = df.loc[df['FraudFound_P'] == 0]
plt.figure(figsize=(10,5))
sns.histplot(data = df_no_fraud, x = 'Age', color = 'blue', bins = 65)
sns.histplot(data = df_fraud1, x = 'Age', color = 'red', bins = 65)
plt.title('Age distribution')
plt.legend(["No Fraud", "Fraud"])
plt.ylabel("Num. of claims")
plt.show()

"""From the plot, its clear that the fraudelent claims are given by people with age between 25-35 in general

"""

df['Fault'].value_counts()

df.groupby(['Fault','FraudFound_P']).size().reset_index()

df_pol = df[(df['Fault']=='Policy Holder' )]
PolicyHolder = df_pol['FraudFound_P'].value_counts()
plt.title('claims between fraudster and Policy Holders')
plt.pie(PolicyHolder, labels = ['No Fraud', 'Fraud'],autopct = '%1.2f%%' )
plt.show()

df_third = df[(df['Fault']=='Third Party' )]
PolicyHolder = df_third['FraudFound_P'].value_counts()
plt.title('claims between fraudster and  Third Party Holders')
plt.pie(PolicyHolder, labels = ['No Fraud', 'Fraud'],autopct = '%1.2f%%' )
plt.show()

"""From the plot, we can understand when the faults are of policy holder , then the chance for fraudelent is higher compared to third party faults."""

plt.figure(figsize=(10,5))
sns.histplot(data = df_pol, x = 'Age', color = 'blue', bins = 65)
sns.histplot(data = df_third, x = 'Age', color = 'red',  bins = 65)
plt.title("Age distribution")
plt.legend(["Policy Holder", "Third Party"])
plt.ylabel("Num. of claims")
plt.show()

df.groupby(['PolicyType','FraudFound_P']).size().reset_index()

cats = ['Sedan - All Perils', 'Sedan - Liability', 'Sedan - Collision', 'Utility - All Perils', 'Utility - Liability', 'Utility - Collision',  'Sport - All Perils',   'Sport - Liability','Sport - Collision']
df['TypesPolicy'] = pd.Categorical(df['PolicyType'], categories=cats, ordered=True)
df = df.sort_values('TypesPolicy')

plt.figure(figsize=(20, 8))
labels = ['No Fraud', 'Fraud']
sns.countplot(x="TypesPolicy",hue="FraudFound_P" ,data=df)
plt.legend(labels)
plt.title('Fraud distribution by Policy Type')
plt.xlabel('Type of policy')
plt.ylabel('N. of claims')
plt.show()

df.groupby(['VehicleCategory','FraudFound_P']).size().reset_index().rename(columns = {0: 'Num of claims'})

sns.countplot( x = 'VehicleCategory', hue = 'FraudFound_P', data = df)
plt.title('Distribution of fraudester/non fraudester claims by vehicle category')
plt.legend(['No Fraud','Fraud'])
plt.ylabel('Num. of claims')
plt.show()

"""Sedan vehicle types are used for fraudelent claims than other category of vehicles

"""

df.groupby(['VehiclePrice']).size().reset_index().rename(columns = {0:'Num of claims'})

Category_Fraud = df.groupby(['VehiclePrice','FraudFound_P']).size().reset_index().rename(columns = {0:'Num of claims'})

df['VehiclePrice'].unique()

price = [ 'less than 20000', '20000 to 29000', '30000 to 39000',
        '40000 to 59000', '60000 to 69000','more than 69000']
df['Prices'] = pd.Categorical(df['VehiclePrice'], categories=price, ordered=True)
df = df.sort_values('Prices')

plt.figure(figsize=(5,5))
sns.countplot(x = 'VehiclePrice', hue = 'FraudFound_P', data = df)
plt.xticks(rotation = 55)
plt.title('Distribution of the type of claim among vehicle price class')
plt.legend(['No Fraud','Fraud'])
plt.show()

df.groupby(['FraudFound_P']).size().reset_index().rename(columns={0:'Num'})

fraud_NoFraud = df.FraudFound_P.value_counts().values
labels = ['No_Fraud','Fraud']
plt.pie(fraud_NoFraud, labels = labels, autopct = '%1.2f%%')
plt.title('Ratio of Fraud - No Fraud on total claims')
plt.show()

df.groupby(['RepNumber']).size().reset_index()

sns.countplot(x = 'RepNumber', data = df)

df.groupby(['PastNumberOfClaims','FraudFound_P']).size().reset_index().rename(columns = {0:'Num. of claims'})

NumPastClaims = [ 'none', '1','2 to 4', 'more than 4']
df['NumPastClaims'] = pd.Categorical(df['PastNumberOfClaims'], categories=NumPastClaims, ordered=True)
df = df.sort_values('NumPastClaims')

plt.figure(figsize=(5,5))
sns.countplot(x = 'NumPastClaims', hue = 'FraudFound_P', data = df)
plt.xticks(rotation = 55)
plt.title('Distribution of number of past claims')
plt.legend(['No Fraud','Fraud'], loc ='upper right')
plt.show()

df['AgeOfVehicle'].unique()

df.groupby(['AgeOfVehicle']).size().reset_index().rename(columns = {0:'Num of claims'})

VehicleAge = ['new','2 years','3 years', '4 years', '5 years', '6 years', '7 years', 'more than 7']
df['VehicleAge'] = pd.Categorical(df['AgeOfVehicle'], categories=VehicleAge, ordered=True)
df = df.sort_values('VehicleAge')

plt.figure(figsize=(10,5))
sns.countplot(x = 'VehicleAge', hue = 'FraudFound_P', data = df)
plt.xticks(rotation = 55)
plt.title('Distribution of vehicles\' ages')
plt.legend(['No Fraud','Fraud'], loc ='upper right')
plt.show()

"""As the Age of vehicle increases chances of fraud also increases"""

df['PoliceReportFiled'].value_counts()

df.groupby(['PoliceReportFiled','FraudFound_P']).size().reset_index().rename(columns = {0: 'Num. of claims'})

sns.countplot(x = 'PoliceReportFiled', hue = 'FraudFound_P', data = df)
plt.xticks(rotation = 55)
plt.title('PoliceReportFiled\' Fraud')
plt.legend(['No Fraud','Fraud'], loc ='upper right')
plt.show()

"""When police report is not filed , the chances of fraudelncy is more

"""

df['WitnessPresent'].value_counts()

df.groupby(['WitnessPresent','FraudFound_P']).size().reset_index()

sns.countplot(x = 'WitnessPresent', hue = 'FraudFound_P', data = df)
plt.xticks(rotation = 55)
plt.title('WitnessPresent\' Fraud')
plt.legend(['No Fraud','Fraud'], loc ='upper right')
plt.show()

"""When the witnesses were absent, those cases had more fraudelent claims"""

df['AgentType'].value_counts()

df.groupby(['AgentType','FraudFound_P']).size().reset_index().rename(columns={0:'Num of claims'})

df.groupby(['NumberOfSuppliments','FraudFound_P']).size().reset_index().rename(columns={0:'Num of claims'})

Suppliments = ['none','1 to 2','3 to 5', 'more than 5']
df['Suppliments'] = pd.Categorical(df['NumberOfSuppliments'], categories=Suppliments, ordered=True)
df = df.sort_values('Suppliments')

sns.countplot(x = 'Suppliments', hue = 'FraudFound_P', data = df)
plt.title('Claims by number of suppliments')
plt.legend(['No Fraud','Fraud'])
plt.xlabel('Num of suppliments')
plt.ylabel('Num of claims')
plt.show()

"""When the suppliments are none , the chances of fraudelents increases"""



df['AddressChange_Claim'].unique()

df.groupby(['AddressChange_Claim','FraudFound_P']).size().reset_index().rename(columns={0:'Num of claims'})

AddressChange = ['no change', 'under 6 months', '1 year', '2 to 3 years','4 to 8 years']
df['AddressChange'] = pd.Categorical(df['AddressChange_Claim'], categories=AddressChange, ordered=True)
df = df.sort_values('AddressChange')

sns.countplot(x = 'AddressChange', hue = 'FraudFound_P', data = df)
plt.legend(['No Fraud','Fraud'])
plt.xticks(rotation=55)
plt.ylabel('Num of claims')
plt.show()

df.groupby(['NumberOfCars','FraudFound_P']).size().reset_index().rename(columns={0:'Num of claims'})

sns.countplot(x = 'NumberOfCars', hue = 'FraudFound_P', data = df)
plt.title('Number of cars owned by clients incurred in claims')
plt.legend(['No Fraud','Fraud'])
plt.xticks(rotation=55)
plt.ylabel('Num of claims')
plt.show()

"""From the graph , we can see people with more than 4 car are not doing fraudelant claims"""

sns.countplot(x='Year', hue='FraudFound_P', data=df)
plt.title('Number of claims occured in 1994-1996')
plt.ylabel('Num of claims')
plt.legend(['No Fraud','Fraud'])
plt.show()

""":From the graph, we can understand that as the years move forward the claims and the frauds are decreasing"""

df_new = df.drop(columns= ['MonthName', 'AreaType', 'TypesPolicy', 'Prices', 'NumPastClaims', 'VehicleAge', 'Suppliments', 'AddressChange'])

df_new.info()

"""Removing 0's in DayOfWeekClaimed and MonthClaimed"""

print(df_new.loc[(df['DayOfWeekClaimed']=='0')])
print(df_new.loc[(df['MonthClaimed']=='0')])

df2 = df_new.loc[df['DayOfWeekClaimed']!='0']
df2.reset_index(drop=True, inplace=True)
len(df2)

"""filling the '0' in the age coloumn

"""

print(len(df2[df2['Age']==0]))

"""we have found that a single row have two 0 values in them , so we would delete the entire row rather than filling the null values. Then the age coloumn we will replace with age 16.


"""

for index, value in enumerate(df2['Age']):
        if value == 0:
            df2.loc[index, 'Age'] = 16

print(len(df2[df2['Age']==0]))

print(len(df2.drop_duplicates())==len(df2))

df2 = df2.drop(columns=['PolicyType','PolicyNumber','RepNumber'])

df2 = df2.drop(columns= ['WeekOfMonth', 'DayOfWeekClaimed', 'MonthClaimed', 'WeekOfMonthClaimed', 'Deductible', 'DriverRating', 'Days_Policy_Accident', 'Days_Policy_Claim', 'AgeOfPolicyHolder', 'AgentType', 'AddressChange_Claim','DayOfWeek'])

df2.info()

df2['NumberOfCars'].unique()

"""**ENCODING

**bold text**

# ENCODING
"""

columns_to_encode = ['Month', 'Make', 'AccidentArea', 'Sex', 'MaritalStatus',
                     'Fault', 'VehicleCategory', 'VehiclePrice',
                     'PastNumberOfClaims', 'AgeOfVehicle',
                     'PoliceReportFiled', 'WitnessPresent',
                     'NumberOfSuppliments', 'NumberOfCars', 'BasePolicy']

label_encoders = {}
for column in columns_to_encode:
    le = LabelEncoder()
    df2[column] = le.fit_transform(df2[column])
    label_encoders[column] = le

df2.head()

import pickle
with open('label_encoders.pkl', 'wb') as f:
    pickle.dump(label_encoders, f)
from google.colab import files

files.download('label_encoders.pkl')

"""label encoding"""



df2.head()

df2.dtypes

"""# SCALING

"""

from sklearn.preprocessing import MinMaxScaler
import pickle
from google.colab import files

scaler = MinMaxScaler()
df2[['Age']] = scaler.fit_transform(df2[['Age']])

with open('minmax_scaler.pkl', 'wb') as f:
    pickle.dump(scaler, f)
files.download('minmax_scaler.pkl')

df2.info()

"""# Modeling

Splitting depeendent and independent variables
"""

X = df2.drop(['FraudFound_P'],axis = 1)
y = df2['FraudFound_P']

from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

X.info()

print('No. of rows and columns in x_train : ', X_train.shape)
print('No. of rows and columns in x_test : ', X_test.shape)
print('No. of rows and columns in y_train : ', y_train.shape)
print('No. of rows and columns in y_test : ', y_test.shape)

y_train.value_counts()

y_test.value_counts()

"""Over Sampling"""

#as we found that the data is imbalanced, we try to over sample the data to avoid bias
oversample = SMOTE(sampling_strategy=0.5)
X_over, y_over = oversample.fit_resample(X_train, y_train)
print('After Oversampling:\n',y_over.value_counts())

X_over_train, X_over_test, y_over_train, y_over_test = train_test_split(X_over, y_over, test_size=0.2, random_state=42)

"""Under Sampling"""

#under sampling the data
join_train = pd.concat([X_train, y_train], axis=1)
claim = join_train[join_train['FraudFound_P']==1]
no_claim = join_train[join_train['FraudFound_P']==0]

undersample_noclaim = no_claim.sample(len(claim)*2)
join_train2 = pd.concat([claim,undersample_noclaim])

print("Before Undersample:\n", join_train['FraudFound_P'].value_counts())
print("After Undersample:\n", join_train2['FraudFound_P'].value_counts())

X_under = join_train2.drop(columns='FraudFound_P')
y_under = join_train2['FraudFound_P']

X_under_train, X_under_test, y_under_train, y_under_test = train_test_split(X_under, y_under, test_size=0.2, random_state=42
                                                                            )

"""LR"""

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_over_scaled = scaler.fit_transform(X_over)
X_under_scaled = scaler.fit_transform(X_under)
LR = LogisticRegression(solver='liblinear')
cv_normal = cross_val_score(LR, X_scaled, y, cv=5)
cv_over = cross_val_score(LR, X_over_scaled, y_over, cv=5)
cv_under = cross_val_score(LR, X_under_scaled, y_under, cv=5)

print("Accuracy on normal data",(cv_normal*100 ))
print("Accuracy on over sample data",(cv_over*100 ))
print("Accuracy on under sample data:", cv_under * 100)

from sklearn.metrics import recall_score
from sklearn.metrics import precision_score
from sklearn.metrics import accuracy_score

"""Normal"""

LR_normal = LR.fit(X_train, y_train)
LR_y_normal_pred = LR_normal.predict(X_test)
LR_Acc_normal = accuracy_score(LR_y_normal_pred, y_test)*100
LR_Rec_normal = recall_score(LR_y_normal_pred, y_test)*100
LR_Pre_normal = precision_score(LR_y_normal_pred, y_test)*100

"""Over Sampling"""

LR_over = LogisticRegression()
LR_over = LR.fit(X_over_train, y_over_train)
LR_y_over_pred = LR_over.predict(X_over_test)
LR_Acc_over = accuracy_score(LR_y_over_pred, y_over_test)*100
LR_Rec_over = recall_score(LR_y_over_pred, y_over_test)*100
LR_Pre_over = precision_score(LR_y_over_pred, y_over_test)*100

import pickle
model_filename = 'logistic_regression_model.pkl'
with open(model_filename, 'wb') as model_file:
    pickle.dump(LR_over, model_file)
from google.colab import files
files.download(model_filename)

"""Under Sampling"""

LR_under = LR.fit(X_under_train, y_under_train)
LR_y_under_pred = LR_under.predict(X_under_test)
LR_Acc_under = accuracy_score(LR_y_under_pred, y_under_test)*100
LR_Rec_under = recall_score(LR_y_under_pred, y_under_test)*100
LR_Pre_under = precision_score(LR_y_under_pred, y_under_test)*100

"""SVM
  
"""

from sklearn.svm import SVC
svm = SVC()

"""Normal _ SVM"""

svm_normal = svm.fit(X_train, y_train)
svm_y_normal_pred = svm_normal.predict(X_test)
svm_Acc_normal = accuracy_score(svm_y_normal_pred, y_test)*100
svm_Rec_normal = recall_score(svm_y_normal_pred, y_test)*100
svm_Pre_normal = precision_score(svm_y_normal_pred, y_test)*100

"""SVM- Over

"""

svm_over = svm.fit(X_over_train, y_over_train)
svm_y_over_pred = svm_over.predict(X_test)
svm_Acc_over = accuracy_score(svm_y_over_pred, y_test)*100
svm_Rec_over = recall_score(svm_y_over_pred, y_test)*100
svm_Pre_over = precision_score(svm_y_over_pred, y_test)*100

"""SVM Under"""

svm_under = svm.fit(X_under_train, y_under_train)
svm_y_under_pred = svm_under.predict(X_test)
svm_Acc_under = accuracy_score(svm_y_under_pred, y_test)*100
svm_Rec_under = recall_score(svm_y_under_pred, y_test)*100
svm_Pre_under = precision_score(svm_y_under_pred, y_test)*100

"""Decision Tree"""

from sklearn.tree import DecisionTreeClassifier
DT = DecisionTreeClassifier()

"""Normal"""

DT_normal = DT.fit(X_train, y_train)
DT_y_normal_pred = DT_normal.predict(X_test)
DT_Acc_normal = accuracy_score(DT_y_normal_pred, y_test)*100
DT_Rec_normal = recall_score(DT_y_normal_pred, y_test)*100
DT_Pre_normal = precision_score(DT_y_normal_pred, y_test)*100

"""Decision Tree - over sampling"""

DT_over = DT.fit(X_over_train, y_over_train)
DT_y_over_pred = DT_over.predict(X_test)
DT_Acc_over = accuracy_score(DT_y_over_pred, y_test)*100
DT_Rec_over = recall_score(DT_y_over_pred, y_test)*100
DT_Pre_over = precision_score(DT_y_over_pred, y_test)*100

"""Decision Tree - Under Sampling

"""

DT_under = DT.fit(X_under_train, y_under_train)
DT_y_under_pred = DT_under.predict(X_test)
DT_Acc_under = accuracy_score(DT_y_under_pred, y_test)*100
DT_Rec_under = recall_score(DT_y_under_pred, y_test)*100
DT_Pre_under = precision_score(DT_y_under_pred, y_test)*100

"""RANDOMFOREST"""

from sklearn.ensemble import RandomForestClassifier
RF = RandomForestClassifier()

"""Normal"""

RF_normal = RF.fit(X_train, y_train)
RF_y_normal_pred = RF_normal.predict(X_test)
RF_Acc_normal = accuracy_score(RF_y_normal_pred, y_test)*100
RF_Rec_normal = recall_score(RF_y_normal_pred, y_test)*100
RF_Pre_normal = precision_score(RF_y_normal_pred, y_test)*100

"""Over sampling - RF"""

RF_over = RF.fit(X_over_train, y_over_train)
y_over_pred = RF_over.predict(X_test)
RF_Acc_over = accuracy_score(y_over_pred, y_test)*100
RF_Rec_over = recall_score(y_over_pred, y_test)*100
RF_Pre_over = precision_score(y_over_pred, y_test)*100

"""Under Sampling - RF"""

RF_under = RF.fit(X_under_train, y_under_train)
RF_y_under_pred = RF_under.predict(X_test)
RF_Acc_under = accuracy_score(RF_y_under_pred, y_test)*100
RF_Rec_under = recall_score(RF_y_under_pred, y_test)*100
RF_Pre_under = precision_score(RF_y_under_pred, y_test)*100

"""XGBbooster"""

from xgboost import XGBClassifier
XGB = XGBClassifier()

"""Normal"""

xgb_normal= XGB.fit(X_train, y_train)
xgb_y_normal_pred = xgb_normal.predict(X_test)
xgb_Acc_normal = accuracy_score(xgb_y_normal_pred, y_test) * 100
xgb_Rec_normal = recall_score(xgb_y_normal_pred, y_test) * 100
xgb_Pre_normal = precision_score(xgb_y_normal_pred, y_test) * 100

"""Over Sampling"""

xgb_over = XGB.fit(X_over_train, y_over_train)
xgb_y_over_pred = xgb_over.predict(X_test)
xgb_Acc_over = accuracy_score(xgb_y_over_pred, y_test) * 100
xgb_Rec_over = recall_score(xgb_y_over_pred, y_test) * 100
xgb_Pre_over = precision_score(xgb_y_over_pred, y_test) * 100

"""Under Sampling"""

xgb_under= XGB.fit(X_under_train, y_under_train)
xgb_y_under_pred = xgb_under.predict(X_test)
xgb_Acc_under = accuracy_score(xgb_y_under_pred, y_test) * 100
xgb_Rec_under = recall_score(xgb_y_under_pred, y_test) * 100
xgb_Pre_under = precision_score(xgb_y_under_pred, y_test) * 100

"""Printing All Accuracies"""

data = {'Classifiers': ['LogisticRegression_Normal','SVM_Normal','DecisionTreeClassifier_Normal' ,'RandomForestClassifier_Normal' ,'XGBClassifier_Normal',
                        'LogisticRegression_Over','SVM_Over','DecisionTreeClassifier_Over' ,'RandomForestClassifier_Over' ,'XGBClassifier_Over' ,
                        'LogisticRegression_Under','SVM_Under','DecisionTreeClassifier_Under' ,'RandomForestClassifier_Under' ,'XGBClassifier_Under'],

               'Accuracy': [LR_Acc_normal, svm_Acc_normal,DT_Acc_normal,RF_Acc_normal,xgb_Acc_normal,
                            LR_Acc_over, svm_Acc_over,DT_Acc_over,RF_Acc_over,xgb_Acc_over,
                            LR_Acc_under,svm_Acc_under,DT_Acc_under,RF_Acc_under,xgb_Acc_under],

                'Recall': [LR_Rec_normal, svm_Rec_normal,DT_Rec_normal,RF_Rec_normal,xgb_Rec_normal,
                           LR_Rec_over, svm_Rec_over,DT_Rec_over,RF_Rec_over,xgb_Rec_over,
                           LR_Rec_under,svm_Rec_under,DT_Rec_under,RF_Rec_under,xgb_Rec_under],

                'Preision': [LR_Pre_normal, svm_Pre_normal,DT_Pre_normal,RF_Pre_normal,xgb_Pre_normal,
                             LR_Pre_over, svm_Pre_over,DT_Pre_over,RF_Pre_over,xgb_Pre_over,
                             LR_Pre_under,svm_Pre_under,DT_Pre_under,RF_Pre_under,xgb_Pre_under]
       }
Accuracies = pd.DataFrame(data=data)
Accuracies.set_index('Classifiers', inplace=True)
Accuracies

"""Importing Pickel File"""

import pickle
from google.colab import files

with open('xgb_classifier_model.pkl', 'wb') as file:
    pickle.dump(xgb_normal, file)

file_path = 'xgb_classifier_model.pkl'

files.download(file_path)

